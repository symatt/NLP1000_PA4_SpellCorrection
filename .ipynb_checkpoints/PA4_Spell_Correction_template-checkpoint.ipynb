{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3m9JjeM5U5"
   },
   "source": [
    "# **Programming Assessment \\#4**\n",
    "\n",
    "Names: Go, Wilfred | Sibug, Jordan | Sy, James Matthew\n",
    "\n",
    "More information on the assessment is found in our Canvas course. Link: https://dlsu.instructure.com/courses/93383/assignments/739602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxtmCAZwNoeU"
   },
   "source": [
    "# **Load Data**\n",
    "\n",
    "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CbvxU2oTM4IV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to C:\\Users\\JAMES\n",
      "[nltk_data]     SY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "# load the words from the Gutenberg Document\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# print(\"Extracting all documents from NLTK's Project Gutenberg Collection...\")\n",
    "all_words = Counter()\n",
    "for filename in nltk.corpus.gutenberg.fileids():\n",
    "    words = [word.lower() for word in nltk.corpus.gutenberg.words(filename)]\n",
    "    all_words.update(words)\n",
    "#   print(\"%s; tokens: %d; vocab: %d\" % (filename, len(words), len(set(words))))\n",
    "\n",
    "# print(\"Overall Statistics\")\n",
    "# total_tokens = sum(all_words.values())\n",
    "total_types = len(all_words)\n",
    "\n",
    "# print(\"Total tokens: %d\" % total_tokens)\n",
    "# print(\"Total vocabulary / type: %d\" % total_types)\n",
    "# print(\"Type/token ratio: %.4f\" % (total_types / total_tokens))\n",
    "# print(\"Vocabulary richness: %.4f\" % (total_types / (total_tokens ** (1/2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "soul\n",
      "destiny\n",
      "i\n",
      "near\n",
      "walt\n",
      "133583\n"
     ]
    }
   ],
   "source": [
    "# print the word\n",
    "print(words[500])\n",
    "print(words[100])\n",
    "print(words[664])\n",
    "print(words[32])\n",
    "print(words[10000])\n",
    "print(words[5])\n",
    "\n",
    "# get the count of the word\n",
    "print(all_words[words[500]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8YCZLi-N0uR"
   },
   "source": [
    "# **Noisy Channel Model Implementation**\n",
    "\n",
    "*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below. And while we discussed the general approach in class, kindly describe how you decided to implement the spell correction model. Include any modifications your group made as well. This might be a good spot to place part of your write up.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from http://norvig.com/spell-correct.html\n",
    "def edits1(word):\n",
    "    deletes = [] \n",
    "    deleteEdits = [] \n",
    "    transposes = [] \n",
    "    transposeEdits = []\n",
    "    replaces = [] \n",
    "    replaceEdits = []\n",
    "    inserts = []\n",
    "    insertEdits = []\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "#     [('', 'hte'), ('h', 'te'), ('ht', 'e'), ('hte', '')]\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "# DELETION\n",
    "# '' + 'te' = 'te' \n",
    "# if L[-1] == '': ('>' + R[0])|('>') == >h|>\n",
    "# 'h' + 'e' = 'he'  \n",
    "# (L[-1] + R[0])|(L[-1]) == ht|h\n",
    "# 'ht' + '' = 'ht'\n",
    "# (L[-1] + R[0])|(L[-1]) = te|t\n",
    "    for L,R in splits:\n",
    "        if R:\n",
    "            deletes.append(L + R[1:])\n",
    "            if not L: \n",
    "                deleteEdits.append('>' + str(R[0]) + '|>')\n",
    "            else:\n",
    "                 deleteEdits.append(str(L[-1] + R[0]) + '|' + str(L[-1]))\n",
    "\n",
    "# TRANSPOSITION\n",
    "# [('', 'hte'), ('h', 'te'), ('ht', 'e'), ('hte', '')]\n",
    "# ht|th R[0]+R[1] + '|' + R[1] + R[0]\n",
    "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    for L, R in splits:\n",
    "        if len(R) > 1:\n",
    "            transposes.append(L + R[1] + R[0] + R[2:])\n",
    "            transposeEdits.append(R[0]+R[1] + '|' + R[1] + R[0])\n",
    "# SUBSTITUTION\n",
    "# [('', 'hte'), ('h', 'te'), ('ht', 'e'), ('hte', '')]\n",
    "# e|i \n",
    "# R[0] + '|' + c\n",
    "# \n",
    "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    for L, R in splits:\n",
    "        if R:\n",
    "            for c in letters:\n",
    "                replaces.append(L + c + R[1:])\n",
    "                replaceEdits.append(R[0] + '|' + c)\n",
    "    \n",
    "# INSERTION\n",
    "# [('', 'hte'), ('h', 'te'), ('ht', 'e'), ('hte', '')]\n",
    "# \n",
    "# >|>x if not L '>|>' + c\n",
    "# h|ha str(L[-1]) + '|' + str(L[-1]) + c\n",
    "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    for L, R in splits:\n",
    "        for c in letters:\n",
    "            inserts.append(L + c + R)\n",
    "            if not L:\n",
    "                insertEdits.append('>|>' + c)\n",
    "            else:\n",
    "                insertEdits.append(str(L[-1]) + '|' + str(L[-1]) + c)\n",
    "    \n",
    "    print(deleteEdits)\n",
    "    print(insertEdits)\n",
    "    print(replaceEdits)\n",
    "    \n",
    "    wordsAndEdits = {\n",
    "        'del': deletes,\n",
    "        'tra': transposes,\n",
    "        'sub': replaces,\n",
    "        'ins': inserts,\n",
    "        'delEdits': deleteEdits,\n",
    "        'traEdits': transposeEdits,\n",
    "        'subEdits': replaceEdits,\n",
    "        'insEdits': insertEdits\n",
    "    }\n",
    "#     return set(deletes + transposes + replaces + inserts)\n",
    "    return wordsAndEdits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellCorrect(word):\n",
    "    # check if the word is in the corpus\n",
    "    if word in words:\n",
    "        return \"No error\"\n",
    "\n",
    "    # word should be corrected\n",
    "    # get possible words within edit distance 1\n",
    "    candidates = edits1(word)\n",
    "\n",
    "    candidatesProb = {\n",
    "        'del': [],\n",
    "        'tra': [],\n",
    "        'sub': [],\n",
    "        'ins': []\n",
    "    }\n",
    "#     print(wordsAndEdits)\n",
    "    edit_types = ['del', 'tra', 'sub', 'ins']\n",
    "    \n",
    "# find the probability of the candidate in the corpus\n",
    "    for etype in edit_types:\n",
    "        for candidate in candidates[etype]:\n",
    "            if candidate in words:\n",
    "                candidatesProb[etype].append(all_words[candidate] / total_types)\n",
    "            else:\n",
    "                candidatesProb[etype].append(0)\n",
    "\n",
    "    temp = []\n",
    "# remove the candidates with 0 probability\n",
    "    for etype in edit_types:\n",
    "        i = 0    \n",
    "        while i != len(candidates[etype]):\n",
    "            if candidatesProb[etype][i] == 0:\n",
    "                del candidates[etype][i]\n",
    "                del candidatesProb[etype][i]\n",
    "            else:\n",
    "                temp.append([word, candidates[etype][i], etype, 'x', candidatesProb[etype][i], -1, -1])\n",
    "                i += 1\n",
    "#     candidates[etype + 'Edits'][i]\n",
    "#     print(candidates)\n",
    "#     print(candidatesProb)\n",
    "#     print(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VqKjpUrkOSnC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hte\n",
      "['>h|>', 'ht|h', 'te|t']\n",
      "['>|>a', '>|>b', '>|>c', '>|>d', '>|>e', '>|>f', '>|>g', '>|>h', '>|>i', '>|>j', '>|>k', '>|>l', '>|>m', '>|>n', '>|>o', '>|>p', '>|>q', '>|>r', '>|>s', '>|>t', '>|>u', '>|>v', '>|>w', '>|>x', '>|>y', '>|>z', 'h|ha', 'h|hb', 'h|hc', 'h|hd', 'h|he', 'h|hf', 'h|hg', 'h|hh', 'h|hi', 'h|hj', 'h|hk', 'h|hl', 'h|hm', 'h|hn', 'h|ho', 'h|hp', 'h|hq', 'h|hr', 'h|hs', 'h|ht', 'h|hu', 'h|hv', 'h|hw', 'h|hx', 'h|hy', 'h|hz', 't|ta', 't|tb', 't|tc', 't|td', 't|te', 't|tf', 't|tg', 't|th', 't|ti', 't|tj', 't|tk', 't|tl', 't|tm', 't|tn', 't|to', 't|tp', 't|tq', 't|tr', 't|ts', 't|tt', 't|tu', 't|tv', 't|tw', 't|tx', 't|ty', 't|tz', 'e|ea', 'e|eb', 'e|ec', 'e|ed', 'e|ee', 'e|ef', 'e|eg', 'e|eh', 'e|ei', 'e|ej', 'e|ek', 'e|el', 'e|em', 'e|en', 'e|eo', 'e|ep', 'e|eq', 'e|er', 'e|es', 'e|et', 'e|eu', 'e|ev', 'e|ew', 'e|ex', 'e|ey', 'e|ez']\n",
      "['h|a', 'h|b', 'h|c', 'h|d', 'h|e', 'h|f', 'h|g', 'h|h', 'h|i', 'h|j', 'h|k', 'h|l', 'h|m', 'h|n', 'h|o', 'h|p', 'h|q', 'h|r', 'h|s', 'h|t', 'h|u', 'h|v', 'h|w', 'h|x', 'h|y', 'h|z', 't|a', 't|b', 't|c', 't|d', 't|e', 't|f', 't|g', 't|h', 't|i', 't|j', 't|k', 't|l', 't|m', 't|n', 't|o', 't|p', 't|q', 't|r', 't|s', 't|t', 't|u', 't|v', 't|w', 't|x', 't|y', 't|z', 'e|a', 'e|b', 'e|c', 'e|d', 'e|e', 'e|f', 'e|g', 'e|h', 'e|i', 'e|j', 'e|k', 'e|l', 'e|m', 'e|n', 'e|o', 'e|p', 'e|q', 'e|r', 'e|s', 'e|t', 'e|u', 'e|v', 'e|w', 'e|x', 'e|y', 'e|z']\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>candidate</th>\n",
       "      <th>edit_type</th>\n",
       "      <th>edit</th>\n",
       "      <th>P(c)</th>\n",
       "      <th>P(w|c)</th>\n",
       "      <th>P(c) x P(w|c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hte</td>\n",
       "      <td>he</td>\n",
       "      <td>del</td>\n",
       "      <td>x</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hte</td>\n",
       "      <td>the</td>\n",
       "      <td>tra</td>\n",
       "      <td>x</td>\n",
       "      <td>3.155082</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hte</td>\n",
       "      <td>ate</td>\n",
       "      <td>sub</td>\n",
       "      <td>x</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hte</td>\n",
       "      <td>hoe</td>\n",
       "      <td>sub</td>\n",
       "      <td>x</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hte</td>\n",
       "      <td>hue</td>\n",
       "      <td>sub</td>\n",
       "      <td>x</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hte</td>\n",
       "      <td>hate</td>\n",
       "      <td>ins</td>\n",
       "      <td>x</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word candidate edit_type edit      P(c)  P(w|c)  P(c) x P(w|c)\n",
       "0  hte        he       del    x  0.610714      -1             -1\n",
       "1  hte       the       tra    x  3.155082      -1             -1\n",
       "2  hte       ate       sub    x  0.000968      -1             -1\n",
       "3  hte       hoe       sub    x  0.000378      -1             -1\n",
       "4  hte       hue       sub    x  0.000614      -1             -1\n",
       "5  hte      hate       ins    x  0.004322      -1             -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = input(\"Input: \")\n",
    "\n",
    "# call functions, return answer\n",
    "output = spellCorrect(word)\n",
    "print(\"Output: \")\n",
    "headers = ['word', 'candidate', 'edit_type', 'edit', 'P(c)', 'P(w|c)', 'P(c) x P(w|c)']\n",
    "display(pandas.DataFrame(output, columns = headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n"
     ]
    }
   ],
   "source": [
    "test = 'w'\n",
    "print(test[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3smvUR6OXUa"
   },
   "source": [
    "# **Your Relfection / Takeaway / Analysis**\n",
    "\n",
    "*Kindly place the rest of your write up. More information is found in the Canvas write up.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PA4_Spell_Correction_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
